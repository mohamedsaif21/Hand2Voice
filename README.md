# SignLink AI App (Hand2Voice)

 Project Overview

The SignLink AI App is a smart communication tool designed to bridge the gap between the deaf, mute, and hearing communities. It enables real-time translation between Indian Sign Language (ISL) and text/speech using AI and a mobile-friendly interface.

The project consists of two main modules:

- **Sign-to-Text**: Converts ISL gestures captured from the mobile camera into text using AI-based hand gesture recognition.
- **Text-to-Sign**: Converts typed or spoken text into simple sign animations or GIFs, helping users understand and learn ISL signs visually.

This app uses React Native (Expo) for the front end and Firebase for the backend to manage authentication, data storage, and animation assets. The AI models are built using TensorFlow and MediaPipe, optimized for mobile with TFLite.

The project aims to promote inclusive communication and make sign language translation accessible to everyone through an intuitive, easy-to-use mobile experience.

##  Tech Stack

- Frontend: React Native (Expo Go)
- Backend: Firebase (Firestore, Storage, Authentication)
- AI / ML: TensorFlow, MediaPipe, TFLite
- Animations: LottieFiles / Free GIFs
- Platform: Android (Expo Go compatible)

##  Features

- Real-time Sign-to-Text translation
- Smooth Text-to-Sign animations
- Login / Signup authentication
- History tracking for translations
- Voice-to-text input (optional)
- Simple and clean UI built in Figma

##  Goal

To build a fully functional, mobile-first AI-powered Sign Language Translator that enhances communication accessibility and learning for deaf and mute individuals.

---

> This README was added programmatically by your assistant. Update it as needed.
